{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# COUNT DEPLOYED BY NANDINI LOKESH REDDY @MIND-LABS "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD3EEfKzFftV",
        "outputId": "f64180fa-cdeb-45b3-c9c6-79a63b3ea960"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Apr 19 12:28:59 2024       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.147.05   Driver Version: 525.147.05   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
            "|  0%   50C    P8    18W / 390W |      6MiB / 12288MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      2445      G   /usr/lib/xorg/Xorg                  4MiB |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AO4MWPmnFk7m",
        "outputId": "8ab8afce-0852-4701-fb20-57cc9f6d4e32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/pratishthit/Desktop/Count\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZkBCNk9F6NO"
      },
      "source": [
        "## Download video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Y3DjvPRiGIht"
      },
      "outputs": [],
      "source": [
        "SOURCE_VIDEO_PATH = \"./fish-video1.avi\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "631Iddu2oVgZ",
        "outputId": "8cfbf83e-9684-4c11-c79d-b120b235a5bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ultralytics in /home/pratishthit/anaconda3/lib/python3.9/site-packages (8.1.29)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from ultralytics) (4.66.2)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from ultralytics) (10.2.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from ultralytics) (4.9.0.80)\n",
            "Requirement already satisfied: psutil in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from ultralytics) (5.9.8)\n",
            "Requirement already satisfied: torch>=1.8.0 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from ultralytics) (2.2.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from ultralytics) (3.8.3)\n",
            "Requirement already satisfied: py-cpuinfo in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from ultralytics) (1.12.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from ultralytics) (2.2.1)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from ultralytics) (0.17.1)\n",
            "Requirement already satisfied: thop>=0.1.1 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from ultralytics) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (1.23.5)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (6.3.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (4.50.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (2.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (2.19.3)\n",
            "Requirement already satisfied: triton==2.2.0 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (2.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: networkx in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (4.10.0)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
            "Requirement already satisfied: jinja2 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
            "Requirement already satisfied: filelock in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
            "Requirement already satisfied: fsspec in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (2024.3.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: sympy in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.4.99)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics) (3.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2kB2mCmGPmL",
        "outputId": "ce12c92e-1e6e-421d-ff9e-ca3d5762d07d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.1.29 🚀 Python-3.9.13 torch-2.2.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3080, 12045MiB)\n",
            "Setup complete ✅ (16 CPUs, 31.2 GB RAM, 377.6/915.3 GB disk)\n"
          ]
        }
      ],
      "source": [
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyQZ4jfrqwx0",
        "outputId": "5036f7c6-7f7c-4b64-d58f-fb3cf5cb4026"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: supervision in /home/pratishthit/anaconda3/lib/python3.9/site-packages (0.19.0)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from supervision) (0.7.1)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from supervision) (1.12.0)\n",
            "Requirement already satisfied: pillow>=9.4 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from supervision) (10.2.0)\n",
            "Requirement already satisfied: matplotlib>=3.6.0 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from supervision) (3.8.3)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from supervision) (6.0.1)\n",
            "Requirement already satisfied: opencv-python-headless>=4.5.5.64 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from supervision) (4.9.0.80)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from supervision) (1.23.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.6.0->supervision) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.6.0->supervision) (3.1.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.6.0->supervision) (6.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.6.0->supervision) (2.9.0.post0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.6.0->supervision) (4.50.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.6.0->supervision) (0.12.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.6.0->supervision) (1.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.6.0->supervision) (24.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.6.0->supervision) (3.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /home/pratishthit/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install supervision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ecimh7lYI-g",
        "outputId": "59c773d2-009f-4d68-8c14-0b0a5f903ad9",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "supervision.__version__: 0.19.0\n"
          ]
        }
      ],
      "source": [
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import supervision as sv\n",
        "print(\"supervision.__version__:\", sv.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y99ZDFi4G9zU"
      },
      "source": [
        "## Load pre-trained YOLOv8 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uxe67PQVHBCA"
      },
      "outputs": [],
      "source": [
        "MODEL = \"best.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-7SBD_bHDuQ",
        "outputId": "037e7c77-a22c-4dab-9061-8a4771e77c2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YOLOv8m-seg summary (fused): 245 layers, 27226437 parameters, 0 gradients, 110.0 GFLOPs\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(MODEL)\n",
        "model.fuse()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COTWRxDhHIz3"
      },
      "source": [
        "## Predict and annotate single frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QEx7Wn7F9Tlc"
      },
      "outputs": [],
      "source": [
        "# dict maping class_id to class_name\n",
        "CLASS_NAMES_DICT = model.model.names\n",
        "\n",
        "# class_ids of interest - car, motorcycle, bus and truck\n",
        "selected_classes = [0, 1, 2, 3, 4, 5, 6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43GdCI2HXCYH",
        "outputId": "247f5f83-cb9f-4cbc-eb3a-d5c1dd0d589f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'flounder-witch',\n",
              " 1: 'flounder-witch-bottom',\n",
              " 2: 'haddock',\n",
              " 3: 'hake-red',\n",
              " 4: 'hake-silver',\n",
              " 5: 'pollock',\n",
              " 6: 'redfish'}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "CLASS_NAMES_DICT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### NORMAL COUNT USING IN AND OUT  --> OUTPUT: CHECK-1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "7Qwykp5K9VdK"
      },
      "outputs": [],
      "source": [
        "# settings\n",
        "LINE_START = sv.Point(750,150)\n",
        "LINE_END = sv.Point(750, 1500)\n",
        "\n",
        "TARGET_VIDEO_PATH = \"./check1.mp4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTBvc5FDJcyw",
        "outputId": "2947ce94-3458-4f85-de33-61374748d9c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "VideoInfo(width=2048, height=1536, fps=15, total_frames=4544)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "UdnkBZVn9Xyb",
        "outputId": "f7d3e592-fa5a-4ecd-93c3-1986d06f174e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SupervisionWarnings: `track_buffer` in `ByteTrack.__init__` is deprecated and will be remove in `supervision-0.23.0`. Use 'lost_track_buffer' instead.\n",
            "SupervisionWarnings: `track_thresh` in `ByteTrack.__init__` is deprecated and will be remove in `supervision-0.23.0`. Use 'track_activation_threshold' instead.\n",
            "SupervisionWarnings: `match_thresh` in `ByteTrack.__init__` is deprecated and will be remove in `supervision-0.23.0`. Use 'minimum_matching_threshold' instead.\n",
            "SupervisionWarnings: BoxAnnotator is deprecated: `BoxAnnotator` is deprecated and will be removed in `supervision-0.22.0`. Use `BoundingBoxAnnotator` and `LabelAnnotator` instead\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Counts:\n",
            "flounder-witch: 42\n",
            "flounder-witch-bottom: 35\n",
            "haddock: 10\n",
            "hake-red: 55\n",
            "hake-silver: 0\n",
            "pollock: 9\n",
            "redfish: 61\n"
          ]
        }
      ],
      "source": [
        "import cv2# create BYTETracker instance\n",
        "byte_tracker = sv.ByteTrack(track_thresh=0.25, track_buffer=30, match_thresh=0.8, frame_rate=30)\n",
        "\n",
        "# create VideoInfo instance\n",
        "video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "\n",
        "# create frame generator\n",
        "generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "\n",
        "# create LineZone instance, it is previously called LineCounter class\n",
        "line_zone = sv.LineZone(start=LINE_START, end=LINE_END)\n",
        "\n",
        "# create instance of BoxAnnotator\n",
        "box_annotator = sv.BoxAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
        "\n",
        "# create instance of TraceAnnotator\n",
        "trace_annotator = sv.TraceAnnotator(thickness=4, trace_length=50)\n",
        "\n",
        "# create LineZoneAnnotator instance, it is previously called LineCounterAnnotator class\n",
        "line_zone_annotator = sv.LineZoneAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
        "\n",
        "# Define a dictionary to store class counts\n",
        "class_counts = {}\n",
        "\n",
        "# Define a dictionary to store unique tracking IDs for each class\n",
        "class_tracking_ids = {class_name: set() for class_id, class_name in model.model.names.items()}\n",
        "\n",
        "# define call back function to be used in video processing\n",
        "def callback(frame: np.ndarray, index:int) -> np.ndarray:\n",
        "    global class_counts, class_tracking_ids\n",
        "    # model prediction on single frame and conversion to supervision Detections\n",
        "    results = model(frame, verbose=False)[0]\n",
        "    detections = sv.Detections.from_ultralytics(results)\n",
        "    # only consider class id from selected_classes define above\n",
        "    detections = detections[np.isin(detections.class_id, selected_classes)]\n",
        "    # tracking detections\n",
        "    detections = byte_tracker.update_with_detections(detections)\n",
        "\n",
        "    # Update class counts based on tracking IDs\n",
        "    for class_id, tracker_id in zip(detections.class_id, detections.tracker_id):\n",
        "        class_name = model.model.names[class_id]\n",
        "        class_tracking_ids[class_name].add(tracker_id)\n",
        "\n",
        "    labels = [\n",
        "        f\"#{tracker_id} {model.model.names[class_id]} {confidence:0.2f}\"\n",
        "        for confidence, class_id, tracker_id\n",
        "        in zip(detections.confidence, detections.class_id, detections.tracker_id)\n",
        "    ]\n",
        "    annotated_frame = trace_annotator.annotate(\n",
        "        scene=frame.copy(),\n",
        "        detections=detections\n",
        "    )\n",
        "    annotated_frame=box_annotator.annotate(\n",
        "        scene=annotated_frame,\n",
        "        detections=detections,\n",
        "        labels=labels)\n",
        "\n",
        "    # Count unique tracking IDs for each class\n",
        "    class_counts = {class_name: len(tracking_ids) for class_name, tracking_ids in class_tracking_ids.items()}\n",
        "\n",
        "    # # Add class counts in a text box at the top right corner of the video\n",
        "    # for idx, (class_name, count) in enumerate(class_counts.items()):\n",
        "    #     text = f\"{class_name}: {count}\"\n",
        "    #     text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]\n",
        "    #     text_x = annotated_frame.shape[1] - 20 - text_size[0]\n",
        "    #     text_y = 40 + idx * (text_size[1] + 20)\n",
        "    #     cv2.putText(annotated_frame, text, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "    # update line counter\n",
        "    line_zone.trigger(detections)\n",
        "    # return frame with box and line annotated result\n",
        "    return line_zone_annotator.annotate(annotated_frame, line_counter=line_zone)\n",
        "\n",
        "# process the whole video\n",
        "sv.process_video(\n",
        "    source_path = SOURCE_VIDEO_PATH,\n",
        "    target_path = TARGET_VIDEO_PATH,\n",
        "    callback=callback\n",
        ")\n",
        "\n",
        "# Print class counts after video processing\n",
        "print(\"Class Counts:\")\n",
        "for class_name, count in class_counts.items():\n",
        "    print(f\"{class_name}: {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### WITHOUT IN AND OUT\" JUST WITH THE CLASS NAMES: WORKS WELL --> OUTPUT IN CHECK-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "-gEzyXVZYI-s"
      },
      "outputs": [],
      "source": [
        "\n",
        "from typing import Dict, Iterable, Optional, Tuple\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from supervision.detection.core import Detections\n",
        "from supervision.draw.color import Color\n",
        "from supervision.draw.utils import draw_text\n",
        "from supervision.geometry.core import Point, Position, Vector\n",
        "\n",
        "\n",
        "class LineZone:\n",
        "\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        start: Point,\n",
        "        end: Point,\n",
        "        triggering_anchors: Iterable[Position] = (\n",
        "            Position.TOP_LEFT,\n",
        "            Position.TOP_RIGHT,\n",
        "            Position.BOTTOM_LEFT,\n",
        "            Position.BOTTOM_RIGHT,\n",
        "        ),\n",
        "    ):\n",
        "\n",
        "        self.vector = Vector(start=start, end=end)\n",
        "        self.limits = self.calculate_region_of_interest_limits(vector=self.vector)\n",
        "        self.tracker_state: Dict[str, bool] = {}\n",
        "        self.in_count: int = 0\n",
        "        self.out_count: int = 0\n",
        "        self.triggering_anchors = triggering_anchors\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_region_of_interest_limits(vector: Vector) -> Tuple[Vector, Vector]:\n",
        "        magnitude = vector.magnitude\n",
        "\n",
        "        if magnitude == 0:\n",
        "            raise ValueError(\"The magnitude of the vector cannot be zero.\")\n",
        "\n",
        "        delta_x = vector.end.x - vector.start.x\n",
        "        delta_y = vector.end.y - vector.start.y\n",
        "\n",
        "        unit_vector_x = delta_x / magnitude\n",
        "        unit_vector_y = delta_y / magnitude\n",
        "\n",
        "        perpendicular_vector_x = -unit_vector_y\n",
        "        perpendicular_vector_y = unit_vector_x\n",
        "\n",
        "        start_region_limit = Vector(\n",
        "            start=vector.start,\n",
        "            end=Point(\n",
        "                x=vector.start.x + perpendicular_vector_x,\n",
        "                y=vector.start.y + perpendicular_vector_y,\n",
        "            ),\n",
        "        )\n",
        "        end_region_limit = Vector(\n",
        "            start=vector.end,\n",
        "            end=Point(\n",
        "                x=vector.end.x - perpendicular_vector_x,\n",
        "                y=vector.end.y - perpendicular_vector_y,\n",
        "            ),\n",
        "        )\n",
        "        return start_region_limit, end_region_limit\n",
        "\n",
        "    @staticmethod\n",
        "    def is_point_in_limits(point: Point, limits: Tuple[Vector, Vector]) -> bool:\n",
        "        cross_product_1 = limits[0].cross_product(point)\n",
        "        cross_product_2 = limits[1].cross_product(point)\n",
        "        return (cross_product_1 > 0) == (cross_product_2 > 0)\n",
        "\n",
        "    def trigger(self, detections: Detections) -> Tuple[np.ndarray, np.ndarray]:\n",
        "\n",
        "        crossed_in = np.full(len(detections), False)\n",
        "        crossed_out = np.full(len(detections), False)\n",
        "\n",
        "        if len(detections) == 0:\n",
        "            return crossed_in, crossed_out\n",
        "\n",
        "        all_anchors = np.array(\n",
        "            [\n",
        "                detections.get_anchors_coordinates(anchor)\n",
        "                for anchor in self.triggering_anchors\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        for i, tracker_id in enumerate(detections.tracker_id):\n",
        "            if tracker_id is None:\n",
        "                continue\n",
        "\n",
        "            box_anchors = [Point(x=x, y=y) for x, y in all_anchors[:, i, :]]\n",
        "\n",
        "            in_limits = all(\n",
        "                [\n",
        "                    self.is_point_in_limits(point=anchor, limits=self.limits)\n",
        "                    for anchor in box_anchors\n",
        "                ]\n",
        "            )\n",
        "\n",
        "            if not in_limits:\n",
        "                continue\n",
        "\n",
        "            triggers = [\n",
        "                self.vector.cross_product(point=anchor) < 0 for anchor in box_anchors\n",
        "            ]\n",
        "\n",
        "            if len(set(triggers)) == 2:\n",
        "                continue\n",
        "\n",
        "            tracker_state = triggers[0]\n",
        "\n",
        "            if tracker_id not in self.tracker_state:\n",
        "                self.tracker_state[tracker_id] = tracker_state\n",
        "                continue\n",
        "\n",
        "            if self.tracker_state.get(tracker_id) == tracker_state:\n",
        "                continue\n",
        "\n",
        "            self.tracker_state[tracker_id] = tracker_state\n",
        "            if tracker_state:\n",
        "                self.in_count += 1\n",
        "                crossed_in[i] = True\n",
        "            else:\n",
        "                self.out_count += 1\n",
        "                crossed_out[i] = True\n",
        "\n",
        "        return crossed_in, crossed_out\n",
        "\n",
        "\n",
        "class LineZoneAnnotator:\n",
        "    def __init__(\n",
        "        self,\n",
        "        thickness: float = 2,\n",
        "        color: Color = Color.WHITE,\n",
        "        text_thickness: float = 2,\n",
        "        text_color: Color = Color.BLACK,\n",
        "        text_scale: float = 0.5,\n",
        "        text_offset: float = 1.5,\n",
        "        text_padding: int = 10,\n",
        "        custom_in_text: Optional[str] = None,\n",
        "        custom_out_text: Optional[str] = None,\n",
        "        display_in_count: bool = True,\n",
        "        display_out_count: bool = True,\n",
        "    ):\n",
        "\n",
        "        self.thickness: float = thickness\n",
        "        self.color: Color = color\n",
        "        self.text_thickness: float = text_thickness\n",
        "        self.text_color: Color = text_color\n",
        "        self.text_scale: float = text_scale\n",
        "        self.text_offset: float = text_offset\n",
        "        self.text_padding: int = text_padding\n",
        "        self.custom_in_text: str = custom_in_text\n",
        "        self.custom_out_text: str = custom_out_text\n",
        "        self.display_in_count: bool = display_in_count\n",
        "        self.display_out_count: bool = display_out_count\n",
        "\n",
        "    def _annotate_count(\n",
        "        self,\n",
        "        frame: np.ndarray,\n",
        "        center_text_anchor: Point,\n",
        "        text: str,\n",
        "        is_in_count: bool,\n",
        "    ) -> None:\n",
        "\n",
        "        _, text_height = cv2.getTextSize(\n",
        "            text, cv2.FONT_HERSHEY_SIMPLEX, self.text_scale, self.text_thickness\n",
        "        )[0]\n",
        "\n",
        "        if is_in_count:\n",
        "            center_text_anchor.y -= int(self.text_offset * text_height)\n",
        "        else:\n",
        "            center_text_anchor.y += int(self.text_offset * text_height)\n",
        "\n",
        "        draw_text(\n",
        "            scene=frame,\n",
        "            text=text,\n",
        "            text_anchor=center_text_anchor,\n",
        "            text_color=self.text_color,\n",
        "            text_scale=self.text_scale,\n",
        "            text_thickness=self.text_thickness,\n",
        "            text_padding=self.text_padding,\n",
        "            background_color=self.color,\n",
        "        )\n",
        "    def annotate(self, frame: np.ndarray, line_counter: LineZone) -> np.ndarray:\n",
        "\n",
        "        cv2.line(\n",
        "            frame,\n",
        "            line_counter.vector.start.as_xy_int_tuple(),\n",
        "            line_counter.vector.end.as_xy_int_tuple(),\n",
        "            self.color.as_bgr(),\n",
        "            self.thickness,\n",
        "            lineType=cv2.LINE_AA,\n",
        "            shift=0,\n",
        "        )\n",
        "        cv2.circle(\n",
        "            frame,\n",
        "            line_counter.vector.start.as_xy_int_tuple(),\n",
        "            radius=5,\n",
        "            color=self.text_color.as_bgr(),\n",
        "            thickness=-1,\n",
        "            lineType=cv2.LINE_AA,\n",
        "        )\n",
        "        cv2.circle(\n",
        "            frame,\n",
        "            line_counter.vector.end.as_xy_int_tuple(),\n",
        "            radius=5,\n",
        "            color=self.text_color.as_bgr(),\n",
        "            thickness=-1,\n",
        "            lineType=cv2.LINE_AA,\n",
        "        )\n",
        "\n",
        "        return frame\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "TARGET_VIDEO_PATH = \"./check2.mp4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SupervisionWarnings: `track_buffer` in `ByteTrack.__init__` is deprecated and will be remove in `supervision-0.23.0`. Use 'lost_track_buffer' instead.\n",
            "SupervisionWarnings: `track_thresh` in `ByteTrack.__init__` is deprecated and will be remove in `supervision-0.23.0`. Use 'track_activation_threshold' instead.\n",
            "SupervisionWarnings: `match_thresh` in `ByteTrack.__init__` is deprecated and will be remove in `supervision-0.23.0`. Use 'minimum_matching_threshold' instead.\n",
            "SupervisionWarnings: BoxAnnotator is deprecated: `BoxAnnotator` is deprecated and will be removed in `supervision-0.22.0`. Use `BoundingBoxAnnotator` and `LabelAnnotator` instead\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Counts:\n",
            "flounder-witch: 42\n",
            "flounder-witch-bottom: 35\n",
            "haddock: 10\n",
            "hake-red: 55\n",
            "hake-silver: 0\n",
            "pollock: 9\n",
            "redfish: 61\n"
          ]
        }
      ],
      "source": [
        "import cv2# create BYTETracker instance\n",
        "byte_tracker = sv.ByteTrack(track_thresh=0.25, track_buffer=30, match_thresh=0.8, frame_rate=30)\n",
        "\n",
        "# create VideoInfo instance\n",
        "video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "\n",
        "# create frame generator\n",
        "generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "\n",
        "# create LineZone instance, it is previously called LineCounter class\n",
        "line_zone = LineZone(start=LINE_START, end=LINE_END)\n",
        "\n",
        "# create instance of BoxAnnotator\n",
        "box_annotator = sv.BoxAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
        "\n",
        "# create instance of TraceAnnotator\n",
        "trace_annotator = sv.TraceAnnotator(thickness=4, trace_length=50)\n",
        "\n",
        "# create LineZoneAnnotator instance, it is previously called LineCounterAnnotator class\n",
        "line_zone_annotator = LineZoneAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
        "\n",
        "# Define a dictionary to store class counts\n",
        "class_counts = {}\n",
        "\n",
        "# Define a dictionary to store unique tracking IDs for each class\n",
        "class_tracking_ids = {class_name: set() for class_id, class_name in model.model.names.items()}\n",
        "\n",
        "# define call back function to be used in video processing\n",
        "def callback(frame: np.ndarray, index:int) -> np.ndarray:\n",
        "    global class_counts, class_tracking_ids\n",
        "    # model prediction on single frame and conversion to supervision Detections\n",
        "    results = model(frame, verbose=False)[0]\n",
        "    detections = sv.Detections.from_ultralytics(results)\n",
        "    # only consider class id from selected_classes define above\n",
        "    detections = detections[np.isin(detections.class_id, selected_classes)]\n",
        "    # tracking detections\n",
        "    detections = byte_tracker.update_with_detections(detections)\n",
        "\n",
        "    # Update class counts based on tracking IDs\n",
        "    for class_id, tracker_id in zip(detections.class_id, detections.tracker_id):\n",
        "        class_name = model.model.names[class_id]\n",
        "        class_tracking_ids[class_name].add(tracker_id)\n",
        "\n",
        "    labels = [\n",
        "        f\"#{tracker_id} {model.model.names[class_id]} {confidence:0.2f}\"\n",
        "        for confidence, class_id, tracker_id\n",
        "        in zip(detections.confidence, detections.class_id, detections.tracker_id)\n",
        "    ]\n",
        "    annotated_frame = trace_annotator.annotate(\n",
        "        scene=frame.copy(),\n",
        "        detections=detections\n",
        "    )\n",
        "    annotated_frame=box_annotator.annotate(\n",
        "        scene=annotated_frame,\n",
        "        detections=detections,\n",
        "        labels=labels)\n",
        "\n",
        "    # Count unique tracking IDs for each class\n",
        "    class_counts = {class_name: len(tracking_ids) for class_name, tracking_ids in class_tracking_ids.items()}\n",
        "\n",
        "    # Add class counts in a text box at the top right corner of the video\n",
        "    for idx, (class_name, count) in enumerate(class_counts.items()):\n",
        "        text = f\"{class_name}: {count}\"\n",
        "        text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]\n",
        "        text_x = annotated_frame.shape[1] - 20 - text_size[0]\n",
        "        text_y = 40 + idx * (text_size[1] + 20)\n",
        "        cv2.putText(annotated_frame, text, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "    # update line counter\n",
        "    line_zone.trigger(detections)\n",
        "    # return frame with box and line annotated result\n",
        "    return line_zone_annotator.annotate(annotated_frame, line_counter=line_zone)\n",
        "\n",
        "# process the whole video\n",
        "sv.process_video(\n",
        "    source_path = SOURCE_VIDEO_PATH,\n",
        "    target_path = TARGET_VIDEO_PATH,\n",
        "    callback=callback\n",
        ")\n",
        "\n",
        "# Print class counts after video processing\n",
        "print(\"Class Counts:\")\n",
        "for class_name, count in class_counts.items():\n",
        "    print(f\"{class_name}: {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SAVING ONE FRAME FOR EACH FISH {WHEN BOUNDING BOX MEETS THE SPECIFIED LINE}  --> OUTPUT : SAVED_FRAMESCHECK-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Define the folder where frames will be saved\n",
        "frames_folder = \"saved_framesCHECK-2\"\n",
        "\n",
        "# Create the folder if it doesn't exist\n",
        "if not os.path.exists(frames_folder):\n",
        "    os.makedirs(frames_folder)\n",
        "\n",
        "# Define a set to keep track of frames where fish bounding boxes cross the line\n",
        "frames_to_save = set()\n",
        "\n",
        "# define call back function to be used in video processing\n",
        "def callback(frame: np.ndarray, index:int):\n",
        "    global class_counts, class_tracking_ids, frames_to_save\n",
        "    # model prediction on single frame and conversion to supervision Detections\n",
        "    results = model(frame, verbose=False)[0]\n",
        "    detections = sv.Detections.from_ultralytics(results)\n",
        "    # only consider class id from selected_classes define above\n",
        "    detections = detections[np.isin(detections.class_id, selected_classes)]\n",
        "    # tracking detections\n",
        "    detections = byte_tracker.update_with_detections(detections)\n",
        "\n",
        "    # Update class counts based on tracking IDs\n",
        "    for class_id, tracker_id in zip(detections.class_id, detections.tracker_id):\n",
        "        class_name = model.model.names[class_id]\n",
        "        class_tracking_ids[class_name].add(tracker_id)\n",
        "\n",
        "    labels = [\n",
        "        f\"#{tracker_id} {model.model.names[class_id]} {confidence:0.2f}\"\n",
        "        for confidence, class_id, tracker_id\n",
        "        in zip(detections.confidence, detections.class_id, detections.tracker_id)\n",
        "    ]\n",
        "    annotated_frame = trace_annotator.annotate(\n",
        "        scene=frame.copy(),\n",
        "        detections=detections\n",
        "    )\n",
        "    annotated_frame=box_annotator.annotate(\n",
        "        scene=annotated_frame,\n",
        "        detections=detections,\n",
        "        labels=labels)\n",
        "\n",
        "    # Count unique tracking IDs for each class\n",
        "    class_counts = {class_name: len(tracking_ids) for class_name, tracking_ids in class_tracking_ids.items()}\n",
        "\n",
        "    # Add class counts in a text box at the top right corner of the video\n",
        "    for idx, (class_name, count) in enumerate(class_counts.items()):\n",
        "        text = f\"{class_name}: {count}\"\n",
        "        text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]\n",
        "        text_x = annotated_frame.shape[1] - 20 - text_size[0]\n",
        "        text_y = 40 + idx * (text_size[1] + 20)\n",
        "        cv2.putText(annotated_frame, text, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "    # update line counter\n",
        "    crossed_in, crossed_out = line_zone.trigger(detections)\n",
        "    \n",
        "    # Save frames where fish bounding boxes cross the line for the first time\n",
        "    for tracker_id, crossed, class_id in zip(detections.tracker_id, crossed_in, detections.class_id):\n",
        "        if tracker_id is not None and crossed:\n",
        "            if tracker_id not in frames_to_save:\n",
        "                frames_to_save.add(tracker_id)\n",
        "                class_name = model.model.names[class_id]\n",
        "                # Save the frame in the folder with class name and tracker ID in the filename\n",
        "                frame_path = os.path.join(frames_folder, f'frame_{class_name}_{tracker_id}.jpg')\n",
        "                cv2.imwrite(frame_path, frame)\n",
        "\n",
        "\n",
        "    # return frame with box and line annotated result\n",
        "    return line_zone_annotator.annotate(annotated_frame, line_counter=line_zone)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[ERROR:0@3084.285] global cap.cpp:643 open VIDEOIO(CV_IMAGES): raised OpenCV exception:\n",
            "\n",
            "OpenCV(4.9.0) /io/opencv/modules/videoio/src/cap_images.cpp:216: error: (-215:Assertion failed) !filename.empty() in function 'icvExtractPattern'\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Create the folder if it doesn't exist\n",
        "if not os.path.exists(frames_folder):\n",
        "    os.makedirs(frames_folder)\n",
        "\n",
        "\n",
        "# Call the process_video function to process the source video\n",
        "sv.process_video(\n",
        "    source_path=SOURCE_VIDEO_PATH,\n",
        "    target_path=None,  # Setting target_path to None to avoid saving the video\n",
        "    callback=callback\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
